{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경사하강법(Gradient Descent, GD)\n",
    "- 최솟값 구하는 방법 중 하나\n",
    "- Gradient Descent 구현\n",
    "\n",
    "<img src=\"https://nbviewer.jupyter.org/github/engineersCode/EngComp6_deeplearning/blob/master/images/descent.png\n",
    "\" width=\"400\" height=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 머신러닝 알고리즘에서 최적화(Optimizer)는 비용함수의 값이 가장 작아지는 최적의 파라미터를 찾는 과정\n",
    "    - 이를 달성하기 위해서, 경사하강법(Gradient Descent) 기반의 방식이 가장 기본이 되는 알고리즘\n",
    "<br>\n",
    "<br />\n",
    "- Cost Function (비용함수)\n",
    "    - **실제 데이터(위 그림에서 빨간 점) 과 직선 사이의 차이를 줄이는 것**이 목적 \n",
    "    - cost function을 최소로 하는  w 와  b 를 찾아보자.\n",
    "    - 이차함수의 최솟값을 구하는 방법은? : 미분한 지점이 0이 되는 것\n",
    "$$\\text{cost function} = \\frac{1}{N}\\sum_{i=1}^n (y_i - f(x_i))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 참고 : 핸즈온머신러닝 1부-4장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0df79a5982cc5a70553c602a5d43d4cb06524f7080da494cbafac53b4237f0a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
