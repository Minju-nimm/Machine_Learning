{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ 학습 곡선(Learning Curve) ]\n",
    "- 훈련 세트와 검증 세트의 모델 성능을 훈련 세트크기(혹은 훈련 반복)의 함수로 나타냄\n",
    "- 훈련 세트에서 크기가 다른 Sub set를 만들어 모델을 여러 번 훈련 시켜서 그래프 생성\n",
    "\n",
    "- 학습곡선을 통해 과대적합과 과소적합을 분석할 수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과대적합(Overfitting) / 과소적합(Underfitting)\n",
    "- 과대적합 : 모델이 training set에서는 좋은 성능을 보이지만 test set에는 낮은 성능을 보이는 경우\n",
    "    - 매개변수가 많고 표현력이 높은 모델\n",
    "<br>\n",
    "<br />\n",
    "- 과소적합 : training set와 test set 성능 차이가 크지 않지만 모두 낮은 성능을 보이는 경우\n",
    "    - 훈련 데이터가 너무 적은 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 규제\n",
    "- 과대적합을 감소시키는 좋은 방법은 모델을 규제(제한)하는 것\n",
    "- 선형회귀모델에서는 보통 <u>모델의 가중치를 제한</u>함으로써 규제를 가함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 규제 \n",
    "\n",
    "\n",
    "## 1) 릿지 회귀\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 라쏘 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 엘라스틱넷\n",
    "- 릿지 회귀와 라쏘 회귀를 절충한 모델"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0df79a5982cc5a70553c602a5d43d4cb06524f7080da494cbafac53b4237f0a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
